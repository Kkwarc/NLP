{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models import CNN_Clasificator, LSTM__Clasificator\n",
    "from get_embedded_data import get_data_glove_CNN, get_data_glove_LSTM, get_data_tokenizer_MLP, split_data, MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len_sentence = 0\n",
    "# pos = 0\n",
    "# for i, sentence in enumerate(list_of_words):\n",
    "#     max_len_sentence, pos = (len(sentence), i) if len(sentence)>max_len_sentence else (max_len_sentence, pos)\n",
    "# max_len_sentence, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from gensim.models import Word2Vec\n",
    "# # nltk.download('punkt')\n",
    "\n",
    "# import gensim.downloader as api\n",
    "# corpus = api.load('text8')\n",
    "\n",
    "# with open('data_set.csv', 'r', encoding='utf-8') as dh:\n",
    "#     list_of_words = []\n",
    "#     list_of_targets = []\n",
    "#     for i, line in enumerate(dh):\n",
    "#         if i > 0:\n",
    "#             line = line.strip()\n",
    "#             line = line.split('@')\n",
    "#             line[-1] = word_tokenize(line[-1].lower())\n",
    "#             list_of_words.append(line[-1])\n",
    "#             list_of_targets.append(line[1])\n",
    "#     dh.close()\n",
    "\n",
    "# emb_dim = 100\n",
    "\n",
    "# model = Word2Vec(corpus, min_count=1)\n",
    "# model.build_vocab(list_of_words, update=True)\n",
    "# model.train(list_of_words, total_examples=model.corpus_count, epochs=20)\n",
    "# model.save('word2vec_100d')\n",
    "\n",
    "# # model = Word2Vec.load('word2vec/word2vec_100d')\n",
    "\n",
    "# # Access embeddings\n",
    "# word_embeddings = model.wv\n",
    "# print(model.wv.most_similar(\"folly\"))\n",
    "# print(word_embeddings['superstitious'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_embeddings = []\n",
    "# for sentence in list_of_words:\n",
    "#     emb_sentence = np.empty((100,0))\n",
    "#     for word in sentence:\n",
    "#         emb_sentence = np.hstack((emb_sentence, np.reshape(model.wv[word], (100, 1))))\n",
    "#     word2vec_embeddings.append(torch.from_numpy(emb_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchtext\n",
    "# import torchtext.vocab\n",
    "\n",
    "# glove = torchtext.vocab.GloVe(name=\"6B\", dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_inc = []\n",
    "# for i, sen in enumerate(list_of_words):\n",
    "#     counter = 0\n",
    "#     for j, wor in enumerate(sen):\n",
    "#         if wor not in glove:\n",
    "#             counter += 1\n",
    "#     if counter >= 1: list_of_inc.append((i, counter))\n",
    "# print(len(list_of_inc))\n",
    "# list_of_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = []\n",
    "# for i, sen in enumerate(list_of_words):\n",
    "#     for j, wor in enumerate(sen):\n",
    "#             if wor not in glove: abc.append((list_of_targets[i],i, j, wor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miss_by_aut=[]\n",
    "# i = 0\n",
    "# inc = 0\n",
    "# prev_aut = list_of_inc[0][0]\n",
    "# for aut , _, _ in list_of_inc:\n",
    "#     if aut == prev_aut:\n",
    "#         inc += 1\n",
    "#     else:\n",
    "#         miss_by_aut.append([prev_aut, inc])\n",
    "#         prev_aut = aut\n",
    "#         i+=1\n",
    "#         inc = 0\n",
    "# miss_by_aut.append([aut, inc])\n",
    "# miss_by_aut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aristotle' 'freud' 'hegel' 'kant' 'nietzsche' 'plato' 'sartre'\n",
      " 'schopenhauer' 'spinoza']\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\"data_set.csv\", \"author\", \"quote\", test_size=0.2, separator=\"@\", mapping=MAPPING, labels_to_delete=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# dataloader = get_data_BERT_MLP(20, device)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_glove_CNN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m get_data_glove_CNN(\u001b[38;5;241m200\u001b[39m, X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\bgale\\Desktop\\NLP\\get_embedded_data.py:138\u001b[0m, in \u001b[0;36mget_data_glove_CNN\u001b[1;34m(batch, words, labels)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len_of_sentence):\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentence):\n\u001b[1;32m--> 138\u001b[0m         emb_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglove\u001b[49m\u001b[43m[\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m         emb_sentence \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack((emb_sentence, torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m1\u001b[39m))))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dataloader = get_data_BERT_MLP(20, device)\n",
    "train_dataloader = get_data_glove_CNN(200, X_train, y_train)\n",
    "test_dataloader = get_data_glove_CNN(200, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = CNN_Clasificator().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] loss: 0.010 accuracy: 18\n",
      "[2/30] loss: 0.009 accuracy: 21\n",
      "[3/30] loss: 0.009 accuracy: 22\n",
      "[4/30] loss: 0.009 accuracy: 24\n",
      "[5/30] loss: 0.009 accuracy: 26\n",
      "[6/30] loss: 0.009 accuracy: 28\n",
      "[7/30] loss: 0.009 accuracy: 28\n",
      "[8/30] loss: 0.008 accuracy: 32\n",
      "[9/30] loss: 0.008 accuracy: 36\n",
      "[10/30] loss: 0.008 accuracy: 36\n",
      "[11/30] loss: 0.008 accuracy: 40\n",
      "[12/30] loss: 0.007 accuracy: 43\n",
      "[13/30] loss: 0.007 accuracy: 46\n",
      "[14/30] loss: 0.007 accuracy: 49\n",
      "[15/30] loss: 0.006 accuracy: 51\n",
      "[16/30] loss: 0.006 accuracy: 55\n",
      "[17/30] loss: 0.006 accuracy: 56\n",
      "[18/30] loss: 0.005 accuracy: 60\n",
      "[19/30] loss: 0.005 accuracy: 63\n",
      "[20/30] loss: 0.005 accuracy: 65\n",
      "[21/30] loss: 0.005 accuracy: 69\n",
      "[22/30] loss: 0.004 accuracy: 69\n",
      "[23/30] loss: 0.004 accuracy: 71\n",
      "[24/30] loss: 0.004 accuracy: 76\n",
      "[25/30] loss: 0.004 accuracy: 77\n",
      "[26/30] loss: 0.003 accuracy: 77\n",
      "[27/30] loss: 0.003 accuracy: 80\n",
      "[28/30] loss: 0.003 accuracy: 82\n",
      "[29/30] loss: 0.003 accuracy: 84\n",
      "[30/30] loss: 0.002 accuracy: 86\n",
      "Finished Training\n",
      "Test acc: 25.5\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 30\n",
    "network.train()\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = network(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('[%d/%d] loss: %.3f accuracy: %d' %\n",
    "          (epoch+1, max_epoch, running_loss / 2000, 100 * correct / total))\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = network(inputs)\n",
    "    total += labels.size(0)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test acc: {100 * correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_data_glove_LSTM(200, X_train, y_train)\n",
    "test_dataloader = get_data_glove_LSTM(1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = LSTM__Clasificator(60).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(),weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 15.991902834008098\n",
      "[1/70] loss: 0.010 accuracy: 16\n",
      "Test accuracy: 17.813765182186234\n",
      "[2/70] loss: 0.009 accuracy: 17\n",
      "Test accuracy: 18.016194331983804\n",
      "[3/70] loss: 0.009 accuracy: 17\n",
      "Test accuracy: 17.408906882591094\n",
      "[4/70] loss: 0.009 accuracy: 18\n",
      "Test accuracy: 19.02834008097166\n",
      "[5/70] loss: 0.009 accuracy: 19\n",
      "Test accuracy: 20.445344129554655\n",
      "[6/70] loss: 0.009 accuracy: 22\n",
      "Test accuracy: 22.06477732793522\n",
      "[7/70] loss: 0.009 accuracy: 22\n",
      "Test accuracy: 23.88663967611336\n",
      "[8/70] loss: 0.009 accuracy: 23\n",
      "Test accuracy: 24.898785425101213\n",
      "[9/70] loss: 0.009 accuracy: 26\n",
      "Test accuracy: 24.493927125506072\n",
      "[10/70] loss: 0.009 accuracy: 27\n",
      "Test accuracy: 26.31578947368421\n",
      "[11/70] loss: 0.009 accuracy: 28\n",
      "Test accuracy: 26.923076923076923\n",
      "[12/70] loss: 0.009 accuracy: 30\n",
      "Test accuracy: 26.31578947368421\n",
      "[13/70] loss: 0.009 accuracy: 29\n",
      "Test accuracy: 27.125506072874494\n",
      "[14/70] loss: 0.009 accuracy: 30\n",
      "Test accuracy: 27.732793522267208\n",
      "[15/70] loss: 0.008 accuracy: 32\n",
      "Test accuracy: 27.530364372469634\n",
      "[16/70] loss: 0.008 accuracy: 32\n",
      "Test accuracy: 26.720647773279353\n",
      "[17/70] loss: 0.008 accuracy: 34\n",
      "Test accuracy: 28.54251012145749\n",
      "[18/70] loss: 0.008 accuracy: 35\n",
      "Test accuracy: 25.506072874493928\n",
      "[19/70] loss: 0.008 accuracy: 34\n",
      "Test accuracy: 28.13765182186235\n",
      "[20/70] loss: 0.008 accuracy: 34\n",
      "Test accuracy: 29.149797570850204\n",
      "[21/70] loss: 0.008 accuracy: 37\n",
      "Test accuracy: 27.93522267206478\n",
      "[22/70] loss: 0.008 accuracy: 38\n",
      "Test accuracy: 28.34008097165992\n",
      "[23/70] loss: 0.008 accuracy: 37\n",
      "Test accuracy: 30.161943319838056\n",
      "[24/70] loss: 0.008 accuracy: 38\n",
      "Test accuracy: 30.161943319838056\n",
      "[25/70] loss: 0.008 accuracy: 39\n",
      "Test accuracy: 29.352226720647774\n",
      "[26/70] loss: 0.007 accuracy: 40\n",
      "Test accuracy: 30.161943319838056\n",
      "[27/70] loss: 0.007 accuracy: 41\n",
      "Test accuracy: 29.554655870445345\n",
      "[28/70] loss: 0.007 accuracy: 42\n",
      "Test accuracy: 29.757085020242915\n",
      "[29/70] loss: 0.007 accuracy: 41\n",
      "Test accuracy: 28.94736842105263\n",
      "[30/70] loss: 0.007 accuracy: 42\n",
      "Test accuracy: 27.93522267206478\n",
      "[31/70] loss: 0.007 accuracy: 42\n",
      "Test accuracy: 29.959514170040485\n",
      "[32/70] loss: 0.007 accuracy: 43\n",
      "Test accuracy: 27.93522267206478\n",
      "[33/70] loss: 0.007 accuracy: 45\n",
      "Test accuracy: 27.732793522267208\n",
      "[34/70] loss: 0.007 accuracy: 44\n",
      "Test accuracy: 29.757085020242915\n",
      "[35/70] loss: 0.007 accuracy: 43\n",
      "Test accuracy: 28.94736842105263\n",
      "[36/70] loss: 0.007 accuracy: 45\n",
      "Test accuracy: 30.5668016194332\n",
      "[37/70] loss: 0.007 accuracy: 46\n",
      "Test accuracy: 30.76923076923077\n",
      "[38/70] loss: 0.007 accuracy: 48\n",
      "Test accuracy: 32.18623481781376\n",
      "[39/70] loss: 0.007 accuracy: 47\n",
      "Test accuracy: 29.149797570850204\n",
      "[40/70] loss: 0.007 accuracy: 48\n",
      "Test accuracy: 29.959514170040485\n",
      "[41/70] loss: 0.007 accuracy: 49\n",
      "Test accuracy: 29.554655870445345\n",
      "[42/70] loss: 0.006 accuracy: 50\n",
      "Test accuracy: 28.74493927125506\n",
      "[43/70] loss: 0.007 accuracy: 48\n",
      "Test accuracy: 29.554655870445345\n",
      "[44/70] loss: 0.006 accuracy: 51\n",
      "Test accuracy: 26.720647773279353\n",
      "[45/70] loss: 0.007 accuracy: 45\n",
      "Test accuracy: 27.530364372469634\n",
      "[46/70] loss: 0.007 accuracy: 44\n",
      "Test accuracy: 26.31578947368421\n",
      "[47/70] loss: 0.007 accuracy: 45\n",
      "Test accuracy: 29.757085020242915\n",
      "[48/70] loss: 0.007 accuracy: 48\n",
      "Test accuracy: 29.352226720647774\n",
      "[49/70] loss: 0.006 accuracy: 51\n",
      "Test accuracy: 30.5668016194332\n",
      "[50/70] loss: 0.006 accuracy: 52\n",
      "Test accuracy: 31.37651821862348\n",
      "[51/70] loss: 0.006 accuracy: 52\n",
      "Test accuracy: 30.5668016194332\n",
      "[52/70] loss: 0.006 accuracy: 52\n",
      "Test accuracy: 30.5668016194332\n",
      "[53/70] loss: 0.006 accuracy: 52\n",
      "Test accuracy: 29.757085020242915\n",
      "[54/70] loss: 0.006 accuracy: 55\n",
      "Test accuracy: 28.94736842105263\n",
      "[55/70] loss: 0.006 accuracy: 55\n",
      "Test accuracy: 30.5668016194332\n",
      "[56/70] loss: 0.006 accuracy: 57\n",
      "Test accuracy: 30.364372469635626\n",
      "[57/70] loss: 0.006 accuracy: 57\n",
      "Test accuracy: 29.554655870445345\n",
      "[58/70] loss: 0.006 accuracy: 56\n",
      "Test accuracy: 30.5668016194332\n",
      "[59/70] loss: 0.006 accuracy: 57\n",
      "Test accuracy: 30.97165991902834\n",
      "[60/70] loss: 0.006 accuracy: 57\n",
      "Test accuracy: 29.757085020242915\n",
      "[61/70] loss: 0.005 accuracy: 58\n",
      "Test accuracy: 27.93522267206478\n",
      "[62/70] loss: 0.005 accuracy: 58\n",
      "Test accuracy: 30.161943319838056\n",
      "[63/70] loss: 0.005 accuracy: 58\n",
      "Test accuracy: 28.54251012145749\n",
      "[64/70] loss: 0.005 accuracy: 60\n",
      "Test accuracy: 30.161943319838056\n",
      "[65/70] loss: 0.005 accuracy: 59\n",
      "Test accuracy: 28.94736842105263\n",
      "[66/70] loss: 0.005 accuracy: 60\n",
      "Test accuracy: 33.19838056680162\n",
      "[67/70] loss: 0.005 accuracy: 62\n",
      "Test accuracy: 28.74493927125506\n",
      "[68/70] loss: 0.005 accuracy: 60\n",
      "Test accuracy: 32.99595141700405\n",
      "[69/70] loss: 0.005 accuracy: 62\n",
      "Test accuracy: 30.364372469635626\n",
      "[70/70] loss: 0.005 accuracy: 63\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 70\n",
    "network.train()\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels, x_len = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        network.prep(200)\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        new_preds = torch.empty((0,9)).to(device)\n",
    "        for i in range(len(outputs)):\n",
    "            new_preds = torch.vstack((new_preds, outputs[i][x_len[i]-1]))\n",
    "\n",
    "        loss = criterion(new_preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(new_preds.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "        inputs, labels, x_len = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        network.prep(1)\n",
    "        outputs = network(inputs)\n",
    "        new_preds = torch.empty((0,9)).to(device)\n",
    "        for i in range(len(outputs)):\n",
    "            new_preds = torch.vstack((new_preds, outputs[i][x_len[i]-1]))\n",
    "        val_total += labels.size(0)\n",
    "        _, predicted = torch.max(new_preds.data, 1)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test accuracy: {100 * val_correct / val_total}\")\n",
    "\n",
    "    print('[%d/%d] loss: %.3f accuracy: %d' %\n",
    "          (epoch+1, max_epoch, running_loss / 2000, 100 * correct / total))\n",
    "    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Test acc: 30.364372469635626\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "#TP, FN, FP\n",
    "dict_for_stat = {\n",
    "    0: [0,0,0],\n",
    "    1: [0,0,0],\n",
    "    2: [0,0,0],\n",
    "    3: [0,0,0],\n",
    "    4: [0,0,0],\n",
    "    5: [0,0,0],\n",
    "    6: [0,0,0],\n",
    "    7: [0,0,0],\n",
    "    8: [0,0,0]\n",
    "}\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    inputs, labels, x_len = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    network.prep(1)\n",
    "    outputs = network(inputs)\n",
    "    new_preds = torch.empty((0,9)).to(device)\n",
    "    for i in range(len(outputs)):\n",
    "        new_preds = torch.vstack((new_preds, outputs[i][x_len[i]-1]))\n",
    "    total += labels.size(0)\n",
    "    _, predicted = torch.max(new_preds.data, 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    for pr, lab in zip(predicted, labels):\n",
    "        pr, lab = pr.item(), lab.item()\n",
    "        if lab == 6: print(1)\n",
    "        if pr == lab:\n",
    "            # TP\n",
    "            dict_for_stat[pr][0] += 1\n",
    "            continue\n",
    "        # FN\n",
    "        dict_for_stat[lab][1] += 1\n",
    "        # FP\n",
    "        dict_for_stat[pr][2] += 1\n",
    "\n",
    "pr_rec_f1 = {}\n",
    "for key in dict_for_stat.keys():\n",
    "    tp, fn, fp = dict_for_stat[key]\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*tp/(2*tp+fn+fp)\n",
    "    pr_rec_f1[key] = [precision, recall, f1_score]\n",
    "\n",
    "print(f\"Test acc: {100 * correct / total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
